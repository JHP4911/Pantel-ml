{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dependent-berkeley",
   "metadata": {},
   "source": [
    "# Random Forest Classification Algorithm\n",
    "\n",
    "- Random forest is a classification and regression algorithm.\n",
    "- It is used to solve classification as well as regression problems.\n",
    "- It is mainly used for classification problems.\n",
    "- Forest is made up of lots of trees and more trees means more robust forest.\n",
    "- Random forest algorithm creates decision trees on data samples.\n",
    "- It gets the prediction from each of them and finally selects the best solution by means of voting.\n",
    "- It is better than the single decision tree because it reduces overfitting  by averaging the result.\n",
    "\n",
    "\n",
    "### Random Forest Algorithm - Assumptions\n",
    "- This algorithm combines multiple trees in order to predict the class of the dataset.\n",
    "- It is possible that some decision trees may produce the correct output while some may not.\n",
    "- There should be some actual variables in the feature variable of the dataset so that it can predict accurate results rather than guessed result.\n",
    "- The predictions from each tree must have very low correlations.\n",
    "\n",
    "\n",
    "### Why to use Random Forest Algorithm\n",
    "- The training time is less when compared to other algorithms.\n",
    "- It predicts the output with high accuracy.\n",
    "- It works well even for large datasets.\n",
    "- Even when large portions of data is missing, it maintains good accuracy.\n",
    "\n",
    "\n",
    "### Random Forest Algorithm - Working\n",
    "Random forest algorithm can be understood from the following steps:\n",
    "- Step 1: First, start with the selection of random samples from the given dataset.\n",
    "- Step 2: Next, the algorithm will construct a decision tree for every sample.\n",
    "- Step 3: In this step, voting will be performed for every predicted result.\n",
    "- Step 4: At last, select the most voted prediction result as the final prediction result.\n",
    "\n",
    "\n",
    "### Applications\n",
    "- ***Banking:*** It is used in this sector in order to identify the loan risk\n",
    "- ***Medicine:*** With the help of this algorithm, disease trends can be analyzed\n",
    "- ***Land Use:*** Areas of similar land use can be identified by this algorithm\n",
    "- ***Marketing:*** Marketing trends can be analyzed by this algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-maryland",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection using Random Forest Algorithm\n",
    "\n",
    "### Objective\n",
    "The prediction model will describe you whether to invest in the proposal or not. Here, we choose to minimize the risk for investing i.e, we aim to minimize investing in proposals for which the loan will not be paid back.\n",
    "\n",
    "### Abstract\n",
    "- In this project, main focus is on credit card fraud detection for in real world. Initially we collect the credit card datasets for trained dataset. Then will provide the user credit card queries for testing data set.\n",
    "- After classification process of random forest algorithm using to the already analysing data set and user provide current dataset. Finally optimizing.\n",
    "- The results indicate about the optimal accuracy for Random Forest are 98.6% respectively the accuracy of the result data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-spider",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scenic-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import  classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "theoretical-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structural-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggressive-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nervous-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "      <td>5217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2226.730305</td>\n",
       "      <td>-0.236087</td>\n",
       "      <td>0.264945</td>\n",
       "      <td>0.827038</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>-0.003246</td>\n",
       "      <td>0.182904</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>-0.031792</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027279</td>\n",
       "      <td>-0.152368</td>\n",
       "      <td>-0.040748</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>0.095040</td>\n",
       "      <td>-0.047173</td>\n",
       "      <td>0.034323</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>64.005517</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1389.413821</td>\n",
       "      <td>1.369423</td>\n",
       "      <td>1.159738</td>\n",
       "      <td>1.008941</td>\n",
       "      <td>1.426231</td>\n",
       "      <td>1.189735</td>\n",
       "      <td>1.364610</td>\n",
       "      <td>1.044013</td>\n",
       "      <td>1.184148</td>\n",
       "      <td>0.996248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785643</td>\n",
       "      <td>0.631797</td>\n",
       "      <td>0.365184</td>\n",
       "      <td>0.619756</td>\n",
       "      <td>0.402804</td>\n",
       "      <td>0.491214</td>\n",
       "      <td>0.340083</td>\n",
       "      <td>0.244556</td>\n",
       "      <td>196.030129</td>\n",
       "      <td>0.023975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.168192</td>\n",
       "      <td>-15.732974</td>\n",
       "      <td>-12.389545</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-7.465603</td>\n",
       "      <td>-11.164794</td>\n",
       "      <td>-23.632502</td>\n",
       "      <td>-3.336805</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.273890</td>\n",
       "      <td>-5.707801</td>\n",
       "      <td>-7.996811</td>\n",
       "      <td>-2.512377</td>\n",
       "      <td>-2.322906</td>\n",
       "      <td>-1.338556</td>\n",
       "      <td>-5.336289</td>\n",
       "      <td>-2.909294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1022.000000</td>\n",
       "      <td>-0.994431</td>\n",
       "      <td>-0.313324</td>\n",
       "      <td>0.282338</td>\n",
       "      <td>-0.892458</td>\n",
       "      <td>-0.607498</td>\n",
       "      <td>-0.691254</td>\n",
       "      <td>-0.477109</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>-0.331949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246075</td>\n",
       "      <td>-0.589888</td>\n",
       "      <td>-0.189173</td>\n",
       "      <td>-0.340413</td>\n",
       "      <td>-0.139914</td>\n",
       "      <td>-0.410996</td>\n",
       "      <td>-0.044127</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2136.000000</td>\n",
       "      <td>-0.410106</td>\n",
       "      <td>0.330421</td>\n",
       "      <td>0.857535</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>-0.088854</td>\n",
       "      <td>-0.163031</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.038049</td>\n",
       "      <td>0.274670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097674</td>\n",
       "      <td>-0.174903</td>\n",
       "      <td>-0.047611</td>\n",
       "      <td>0.103070</td>\n",
       "      <td>0.113882</td>\n",
       "      <td>-0.089671</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3494.000000</td>\n",
       "      <td>1.124355</td>\n",
       "      <td>0.914229</td>\n",
       "      <td>1.473973</td>\n",
       "      <td>1.013701</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.581636</td>\n",
       "      <td>0.580912</td>\n",
       "      <td>0.339703</td>\n",
       "      <td>0.807445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070683</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>0.085627</td>\n",
       "      <td>0.444598</td>\n",
       "      <td>0.356538</td>\n",
       "      <td>0.248303</td>\n",
       "      <td>0.168213</td>\n",
       "      <td>0.081684</td>\n",
       "      <td>57.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4999.000000</td>\n",
       "      <td>1.685314</td>\n",
       "      <td>6.224859</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>6.013346</td>\n",
       "      <td>10.658654</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>3.877662</td>\n",
       "      <td>9.272376</td>\n",
       "      <td>...</td>\n",
       "      <td>15.631453</td>\n",
       "      <td>4.393846</td>\n",
       "      <td>4.095021</td>\n",
       "      <td>3.200201</td>\n",
       "      <td>1.972515</td>\n",
       "      <td>3.463246</td>\n",
       "      <td>3.852046</td>\n",
       "      <td>4.157934</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time           V1           V2           V3           V4  \\\n",
       "count  5217.000000  5217.000000  5217.000000  5217.000000  5217.000000   \n",
       "mean   2226.730305    -0.236087     0.264945     0.827038     0.038482   \n",
       "std    1389.413821     1.369423     1.159738     1.008941     1.426231   \n",
       "min       0.000000   -12.168192   -15.732974   -12.389545    -4.657545   \n",
       "25%    1022.000000    -0.994431    -0.313324     0.282338    -0.892458   \n",
       "50%    2136.000000    -0.410106     0.330421     0.857535     0.082108   \n",
       "75%    3494.000000     1.124355     0.914229     1.473973     1.013701   \n",
       "max    4999.000000     1.685314     6.224859     4.101716     6.013346   \n",
       "\n",
       "                V5           V6           V7           V8           V9  ...  \\\n",
       "count  5217.000000  5217.000000  5217.000000  5217.000000  5217.000000  ...   \n",
       "mean     -0.003246     0.182904     0.037771    -0.031792     0.274900  ...   \n",
       "std       1.189735     1.364610     1.044013     1.184148     0.996248  ...   \n",
       "min     -32.092129    -7.465603   -11.164794   -23.632502    -3.336805  ...   \n",
       "25%      -0.607498    -0.691254    -0.477109    -0.192508    -0.331949  ...   \n",
       "50%      -0.088854    -0.163031     0.060510     0.038049     0.274670  ...   \n",
       "75%       0.433500     0.581636     0.580912     0.339703     0.807445  ...   \n",
       "max      10.658654    21.393069    34.303177     3.877662     9.272376  ...   \n",
       "\n",
       "               V21          V22          V23          V24          V25  \\\n",
       "count  5217.000000  5217.000000  5217.000000  5217.000000  5217.000000   \n",
       "mean     -0.027279    -0.152368    -0.040748     0.037787     0.095040   \n",
       "std       0.785643     0.631797     0.365184     0.619756     0.402804   \n",
       "min     -11.273890    -5.707801    -7.996811    -2.512377    -2.322906   \n",
       "25%      -0.246075    -0.589888    -0.189173    -0.340413    -0.139914   \n",
       "50%      -0.097674    -0.174903    -0.047611     0.103070     0.113882   \n",
       "75%       0.070683     0.279351     0.085627     0.444598     0.356538   \n",
       "max      15.631453     4.393846     4.095021     3.200201     1.972515   \n",
       "\n",
       "               V26          V27          V28       Amount        Class  \n",
       "count  5217.000000  5217.000000  5217.000000  5217.000000  5217.000000  \n",
       "mean     -0.047173     0.034323     0.004230    64.005517     0.000575  \n",
       "std       0.491214     0.340083     0.244556   196.030129     0.023975  \n",
       "min      -1.338556    -5.336289    -2.909294     0.000000     0.000000  \n",
       "25%      -0.410996    -0.044127    -0.016606     3.870000     0.000000  \n",
       "50%      -0.089671     0.019557     0.019527    15.250000     0.000000  \n",
       "75%       0.248303     0.168213     0.081684    57.480000     0.000000  \n",
       "max       3.463246     3.852046     4.157934  7712.430000     1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vanilla-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid transaction 5214\n",
      "fraud transaction 3\n"
     ]
    }
   ],
   "source": [
    "print('Valid transaction',len(data[data['Class']==0]))\n",
    "print('fraud transaction',len(data[data['Class']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extraordinary-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Class']\n",
    "x = data.drop(columns=['Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exterior-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train test \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size= 0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "preliminary-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting randomforest model\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lesser-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=20,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_1\n",
    "classifier = RandomForestClassifier(n_estimators=20,criterion='entropy', random_state=0,max_depth=10)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "magnetic-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dirty-spotlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1564\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00      1566\n",
      "   macro avg       0.50      0.50      0.50      1566\n",
      "weighted avg       1.00      1.00      1.00      1566\n",
      "\n",
      "Confusion matrix:\n",
      " [[1564    0]\n",
      " [   2    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Classifcation report:\\n', classification_report(y_test, y_pred))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "formed-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=30,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_2\n",
    "classifier = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solid-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "choice-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1564\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00      1566\n",
      "   macro avg       0.50      0.50      0.50      1566\n",
      "weighted avg       1.00      1.00      1.00      1566\n",
      "\n",
      "Confusion matrix:\n",
      " [[1564    0]\n",
      " [   2    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Classifcation report:\\n', classification_report(y_test, y_pred_2))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred_2)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hybrid-rotation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.14      1564\n",
      "           1       0.00      1.00      0.00         2\n",
      "\n",
      "    accuracy                           0.08      1566\n",
      "   macro avg       0.50      0.54      0.07      1566\n",
      "weighted avg       1.00      0.08      0.14      1566\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 116 1448]\n",
      " [   0    2]]\n"
     ]
    }
   ],
   "source": [
    "# trying with undersmapling technique\n",
    "# This is the pipeline module we need from imblearn for Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = RandomUnderSampler()\n",
    "model = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "\n",
    "\n",
    "# Define the pipeline and combine sampling method with the RF model\n",
    "pipeline = Pipeline([('RandomUnderSampler', resampling), ('RF', model)])\n",
    "pipeline.fit(x_train, y_train) \n",
    "predicted = pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sunset-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1564\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00      1566\n",
      "   macro avg       0.50      0.50      0.50      1566\n",
      "weighted avg       1.00      1.00      1.00      1566\n",
      "\n",
      "Confusion matrix:\n",
      " [[1564    0]\n",
      " [   2    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aditi Patil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# This is the pipeline module we need from imblearn for Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = RandomOverSampler()\n",
    "model = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "\n",
    "# Define the pipeline and combine sampling method with the model\n",
    "pipeline = Pipeline([('RandomOverSampler', resampling), ('RF', model)])\n",
    "pipeline.fit(x_train, y_train) \n",
    "predicted = pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "growing-darkness",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7112d210aab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Define the pipeline and combine sampling method with the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SMOTE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampling\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'RF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m    261\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    224\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m                 )\n\u001b[0;32m    228\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_resample_one\u001b[1;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_resample_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    311\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m             )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# This is the pipeline module we need from imblearn for SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = SMOTE(sampling_strategy='auto',random_state=0)\n",
    "model = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "\n",
    "# Define the pipeline and combine sampling method with the model\n",
    "pipeline = Pipeline([('SMOTE', resampling), ('RF', model)])\n",
    "pipeline.fit(x_train, y_train) \n",
    "predicted = pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "genuine-hobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulalizing the confusion matrix\n",
    "LABELS = ['Normal', 'Fraud'] \n",
    "conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize =(12, 12)) \n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix\") \n",
    "plt.ylabel('True class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
